---------- 1
Good morning/afternoon. I'm Sean Brennan, and I'll be talking about AutonomousTrust - TekFive's concept for cooperative cybersecurity.

Before I launch into explaining what AutonomousTrust is, we'll start with some familiar ground:

---------- 2
*Zero* Trust is a codification of common security best-practices which we should have been doing all along: verifying user identity, device compliance, least privilege, and explicit resource allocation. None of this is new.

ZTA is now a big deal due to a 2021 executive order. But taken to its logical conclusion, this means constant user/device/resource revalidation. The executive order itself is even explicit: "constantly limits access".

In practice, we necessarily fall short and to the extent we fall short, allow breaches. Often the user session is not monitored once authorized.

Also the emphasis is on the Cloud, where this is most easily implemented - "so yesterday". Increasingly seeing computing at the edge; decentralization. 

--------- 3
One option to improve this situtation is IDS (or sometimes IPS [prevention instead of detection]). This is usually achieved through detecting either suspicious patterns (looks improper) or anomalies (doesn't look proper). This can be useful in coherent (i.e. well-patterned, unchanging) security environments (again the Cloud).
The former approach suffers most in resolving false positives due to inherent rigidity, while the latter in resolving false negatives due to watching only local behavior. These blind spots are primarily due to centralization.

--------- 4
In contrast, AutonomousTrust has
• dynamic access levels that change over very short times 
• task-specific, fine-grained responses - not all or nothing (i.e. nothing) 
• is machine-governed, no human input 

--------- 5
We are now departing from normal computing workflow: log in, run commands, or click, click, click, timeout/logoff.

For the moment, think beyond shell access or website interfaces 
and more along the lines of APIs, queries and services.

This is primarily a machine-to-machine paradigm, where the user makes the big decisions, then processes or agents (I'll use them interchangeably) do the grunt work on the user's behalf.

As we proceed, I'm going to use scenarios from Internet of Things (IoT from now on), because that paradigm is predominantly machine-to-machine. As such, device == agent == node.

But I want to stress that this is not an IoT-centric concept, and in fact we foresee it's strongest utility in workflows tying edge computing with cloud computing and everything in-between. 

---------- 6
Let's look at our basic levels of trust and how that directly corresponds to access.

This level is primarily a census of presence in the network. The device participates in, for example, something like ARP, but that's about it.

let's setup our IoT example. It consists of: first, sensory nodes that can deliver live in-situ data; second, coordination nodes that can request different data exposures; and third, inference nodes that can make sense of all the input.

One thing to keep in mind is that this trust graphic is just a one-to-one slice of a many-to-many matrix. 

---------- 8
Messaging can occur, but no tasking.

In our example, roles can be established now, but nothing more. 

---------- 10
Compute services can be requested, effectively sharing CPU resources. Note that finer divisions of access (i.e. which services) can be present at this level.

In our IoT scenario, coordination and inference nodes that have reached this level of trust are fully online. 

---------- 12
Data can now be shared. This is the strongest level of trust, but can also have multiple sub-levels of access within it.

IoT sensors come online: i.e. if coordination nodes reach this level of trust, they can request specific data. 

---------- 13
However, at any time, violation of expectations can cause a drop in reputation, and an immediate loss of access. 

---------- 14
(Here, for instance, a sensor is reporting verifiably out-of-bounds readings - so it is ignored as faulty.)

---------- 15
And a reputation drop can even result in the inability to re-establish contact.

Such as a coordination node that is draining sensor resources. 

---------- 16
At this level, link-layer mechanisms hide a device from an offending peer. 

---------- 17
How does this work? We'll look at seven facets that define how AutonomousTrust does this. 

---------- 18
Network scalability: peer-to-peer with hierarchical connections. Agents further up the hierarchy have greater capabilities: bandwidth, computing, and/or data storage.
Corresponding here to sensors (1) in blue, coordination (2) in orange, and inference (3) in green. 

---------- 19
Common domain language embodied as XML schemas.

For example, sensors use a modality-specific XML schema for reporting readings; coordination primarily uses negotiation protocols to elicit additional data; inference uses a schema that speaks of higher-level phenomena. 

---------- 20
Accomplishing shared goals through cooperation protocols.

Sensors, coordination and inference all need to cooperate yet maintain self-preservation. This is accomplished primarily through negotiation.

---------- 21
Consistent identity through a distributed ledger.
Trust and cooperation is just not possible if identities can be spoofed. 

---------- 22
Reputation-based trust through ledgered transaction scores. A machine social mesh.

In the nominal case, AutonomousTrust is based on reputation. To arrive at a reputation level (from zero to one) for a target peer that we want to interact with, we average transaction scores as reported from other peers, weighted by our remembered reputation level for each of those other peers. A reputation of 0.5 is the threshold for this mode of interaction, because anything less torpedoes everyone else's scores. 
This means we must bootstrap reputations first to even have a remembered reputation. 

---------- 23
Bootstrapping reputations: 
Contrite Tit-for-Tat is an eye-for-an-eye strategy for interaction in the absence of reputation data. In game theory terms, if you defect on me, I defect on you. 'Contrite' means that there is room for forgiveness in case of a mistake. Our graphic indicates that when new peers arrive, some nodes go into tit-for-tat mode to both give the newbies a chance to build reputation, or to protect the rest of the cohort from attack. Attackers are starved out because they cannot gain positive reputation, while trustworthy new nodes are bootstrapped into the populace. 

---------- 24
Opportunity vs safety:
Another protective measure is to go dark and intentionally be unreachable. This degrades the utility of the cohort, but saves the individual. In contrast, enforcement mode is more expensive to the individual in that it engages with the unknown. A preponderance of either is undesirable, so it is important to find a balance and safely maximize the peers in reputation mode. 

---------- 25
This is a snapshot of the Internet, color-coded by geography. Note the scale-free topology which we anticipate to also be a feature of AutonomousTrust.

Our greatest security vulnerability lies in our prerequisite blockchains, and hardening these will be an ongoing challenge.
Some traditional attacks, such as man-in-the-middle, denial-of-service, direct access, or social engineering or spoofing are either inapplicable or trivially neutralized under AutonomousTrust.

We will now look at some *other* possible attack vectors under this paradigm, and how they may be overcome.

---------- 26
Deception:
Here we have a single faulty node; the link weights denote trust levels which change as reputation shifts. Observe the erosion of trust and the ultimate ejection of the bad node. 

---------- 28
Betrayal:
In this one, we have a defector that targets just one other node. Trust erodes here as well, but neither are ejected, because other peers have no knowledge of who is at fault. 

---------- 30
Bad reputation:
This is a coordinated reputation attack by a subset of the cohort. The target is able to bypass this by making contacts with another connected cohort. One thing to note here is that connections can be costly, so all-to-all networks are not likely.

---------- 32
Atomization:
This is another coordinated attack, a Sybil denial of service, where the whole cohort seeks to isolate the target. Again the solution is to make contact with the other cohort. This time the Sybil cohort's reputation suffers once the target is lost, and it is cut-off from the other segment.

---------- 34
Corrupt authority:
Here the contact node in the other cohort ruins attempts to bypass it. The solution is to connect with the next cohort up the hierarchy, effectively changing the network topology. 
